X = []
y = []

for emotion, audio_dir in zip(emotions, audio_dirs):
    audio_paths = glob(os.path.join(audio_dir, '*.wav'))
    for audio_path in audio_paths:
        signal, sr = librosa.load(audio_path, sr=None)
        mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=20)
        X.append(np.mean(mfccs, axis=1))
        y.append(emotion)

X = np.array(X)
y = np.array(y)
